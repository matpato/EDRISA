{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Pre-processing \n",
    "\n",
    "- Organization of the file data-cleaning-and-pre-processing.ipymb:\n",
    "\n",
    "Code 1: Imports\n",
    "\n",
    "Code 2: Read the dataset\n",
    "\n",
    "Code 3: Corrupted rows (rows without the attribute condition)\n",
    "\n",
    "Code 4: Function to clean and preprocess text (atribute review)\n",
    "\n",
    "Code 5: Visualisation of the review (raw and cleaned) in the line 7\n",
    "\n",
    "Code 6: Remove the 'rating' and 'review' attribute\n",
    "\n",
    "Code 7: Export the ds to a CSV file\n",
    "\n",
    "Code 8: Drop the atribute rating from the raw CSV file\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code 1: Imports\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from string import punctuation\n",
    "import re\n",
    "import textwrap \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161297, 7)\n"
     ]
    }
   ],
   "source": [
    "# Code 2: Read the dataset \n",
    "\n",
    "ds = pd.read_csv(r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTrain_raw_or.csv')\n",
    "#ds = pd.read_csv(r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTest_raw.csv')\n",
    "\n",
    "#ds = ds.head(500)\n",
    "print(ds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Corrupted Reviews:  900\n"
     ]
    }
   ],
   "source": [
    "# Code 3: Corrupted rows (rows without the attribute condition)\n",
    "\n",
    "num_corrupted_reviews = len(ds[ds['condition'].str.contains(\"users found this comment helpful.\", na=False)])\n",
    "print(\"Number of Corrupted Reviews: \", num_corrupted_reviews)\n",
    "\n",
    "# Removing corrupted rows based on the attribute condition \n",
    "ds = ds[~ds['condition'].str.contains(\" users found this comment helpful.\", na=False)] #ds is \"ds without ds['condition']...\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 4: Function to clean and preprocess text (atribute review)\n",
    "\n",
    "# Function to map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # default to noun\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML entities and replace with their corresponding character\n",
    "    text = re.sub(r'&#[0-9]+;', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in punctuation])\n",
    "\n",
    "    # Tokenization (just to make sure) \n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Applying POS Tagging\n",
    "    pos_tagged_tokens = pos_tag(filtered_tokens)\n",
    "\n",
    "    # Initialize WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Lemmatization with POS tags\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(pos_tag)) for word, pos_tag in pos_tagged_tokens]\n",
    "    \n",
    "    # Return the processed tokens as a string\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply the preprocessing function to all the review column\n",
    "ds['processed_review'] = ds['review'].apply(preprocess_text)\n",
    "\n",
    "# The 'ds' now has an additional column 'processed_review' with the cleaned text\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw review:\n",
      "\"Abilify changed my life. There is hope. I was on Zoloft and Clonidine when I first started Abilify\n",
      "at the age of 15.. Zoloft for depression and Clondine to manage my complete rage. My moods were out\n",
      "of control. I was depressed and hopeless one second and then mean, irrational, and full of rage the\n",
      "next. My Dr. prescribed me 2mg of Abilify and from that point on I feel like I have been cured\n",
      "though I know I&#039;m not.. Bi-polar disorder is a constant battle. I know Abilify works for me\n",
      "because I have tried to get off it and lost complete control over my emotions. Went back on it and I\n",
      "was golden again.  I am on 5mg 2x daily. I am now 21 and better than I have ever been in the past.\n",
      "Only side effect is I like to eat a lot.\"\n",
      "Processed review:\n",
      "abilify change life hope zoloft clonidine first start abilify age 15 zoloft depression clondine\n",
      "manage complete rage mood control depress hopeless one second mean irrational full rage next dr\n",
      "prescribe 2mg abilify point feel like cure though know im bipolar disorder constant battle know\n",
      "abilify work try get lose complete control emotion go back golden 5mg 2x daily 21 good ever past\n",
      "side effect like eat lot\n"
     ]
    }
   ],
   "source": [
    "# Code 5: Visualisation of the review (raw and cleaned) in the line 7\n",
    "long_review1 = ds['review'].values[7] \n",
    "\n",
    "long_review2 = ds['processed_review'].values[7] \n",
    "\n",
    "# Print a wrapped text for better visualisation\n",
    "print('Raw review:')\n",
    "wrapped_text = textwrap.fill(long_review1, width=100)\n",
    "print(wrapped_text)\n",
    "print('Processed review:')\n",
    "wrapped_text = textwrap.fill(long_review2, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 6: Remove the atribute 'rating' and update the atribute review\n",
    "\n",
    "ds['review'] = ds['processed_review']\n",
    "ds.drop(columns=['processed_review'], inplace=True)\n",
    "ds.drop(columns=['rating'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to 'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTrain_cleaned.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Code 7: Export the ds to a CSV file\n",
    "csv_path = r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTrain_cleaned.csv'\n",
    "#csv_path = r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTest_cleaned.csv'\n",
    "\n",
    "ds.to_csv(csv_path, index=False)\n",
    "print(f\"DataFrame exported to '{csv_path}' successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to 'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTrain_raw.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Code 8: Drop the atribute rating from the raw CSV file\n",
    "\n",
    "ds = pd.read_csv(r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTrain_raw_or.csv')\n",
    "ds.drop(columns=['rating'], inplace=True)\n",
    "\n",
    "csv_path = r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTrain_raw.csv'\n",
    "#csv_path = r'C:\\Users\\Home\\Desktop\\TESE\\MEIC-TFM\\MEIC-TFM\\drugsComTest_raw.csv'\n",
    "\n",
    "ds.to_csv(csv_path, index=False)\n",
    "print(f\"DataFrame exported to '{csv_path}' successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
